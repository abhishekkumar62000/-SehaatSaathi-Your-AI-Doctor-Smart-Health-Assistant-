import os
import streamlit as st
import speech_recognition as sr
import tempfile
from gtts import gTTS
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import SystemMessagePromptTemplate
import base64
from PyPDF2 import PdfReader
from PIL import Image
import pytesseract

load_dotenv()

groq_api_key = os.getenv('GROQ_API_KEY')

st.set_page_config("ğŸ¤–SehaatSaathi-Your AI DoctorğŸ˜·", page_icon="ğŸ§ ", layout="wide")

st.title("ğŸ¤–SehaatSaathi - AI Doctor AssistantğŸ§‘â€âš•ï¸")
st.caption("ğŸš€ Instant Medical Advice & Medicine Recommendations.")

SehaatSaathi_path = "SehaatSaathi.png"  # Ensure this file is in the same directory as your script
try:
    st.sidebar.image(SehaatSaathi_path)
except FileNotFoundError:
    st.sidebar.warning("SehaatSaathi.png file not found. Please check the file path.")
    
Doctor_path = "Doctor.jpg"  # Ensure this file is in the same directory as your script
try:
    st.sidebar.image(Doctor_path)
except FileNotFoundError:
    st.sidebar.warning("Doctor.jpg file not found. Please check the file path.")

with st.sidebar:
    st.header("âš™ Configuration")
    selected_model = st.selectbox("Choose Model", ["deepseek-r1-distill-llama-70b"], index=0)
    language = st.selectbox("Select Response Language", ["English", "Hindi"])

    st.markdown("## SehaatSaathi CapabilitiesğŸ¤·â€â™‚ï¸")
    st.markdown("""
    - ğŸ¤– AI Doctor
    - ğŸ§‘â€âš•ï¸ Health Assistant
    - ğŸ”¬ Symptom Analysis
    - ğŸ’Š Medicine Suggestions
    - ğŸ¥ Health Advice
    """)
    st.markdown("ğŸ‘¨â€ğŸ’» Developer: Abhishek â¤ï¸ Yadav")
    developer_path = "my.jpg"  # Ensure this file is in the same directory as your script
try:
    st.sidebar.image(developer_path)
except FileNotFoundError:
    st.sidebar.warning("my.jpg file not found. Please check the file path.")

ai_doctor = ChatGroq(api_key=groq_api_key, model=selected_model, temperature=0.3)

recognizer = sr.Recognizer()

def speak_text(text, lang="hi"):
    if not isinstance(text, str) or not text.strip():
        return  # Avoid speaking empty or invalid responses
    tts = gTTS(text=text, lang=lang, slow=False)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_audio:
        tts.save(temp_audio.name)
        temp_audio_path = temp_audio.name
    with open(temp_audio_path, "rb") as audio_file:
        audio_bytes = audio_file.read()
        audio_base64 = base64.b64encode(audio_bytes).decode()
    os.remove(temp_audio_path)
    audio_html = f'<audio autoplay="true" controls><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
    st.markdown(audio_html, unsafe_allow_html=True)

def recognize_speech():
    try:
        if not sr.Microphone.list_microphone_names():
            return "âŒ No microphone detected!"
        with sr.Microphone() as source:
            st.info("ğŸ¤ Speak now...")
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source, timeout=5)
            text = recognizer.recognize_google(audio, language="hi-IN")
            return text
    except sr.UnknownValueError:
        return "âŒ Could not understand your voice."
    except sr.RequestError:
        return "âŒ Speech service unavailable."
    except OSError:
        return "âŒ No microphone found!"

def extract_text_from_pdf(pdf_file):
    try:
        pdf_reader = PdfReader(pdf_file)
        text = "\n".join([page.extract_text() or "" for page in pdf_reader.pages])
        return text.strip() if text.strip() else "âŒ No text found in PDF."
    except Exception:
        return "âŒ Error processing PDF."

def extract_text_from_image(image_file):
    try:
        image = Image.open(image_file)
        text = pytesseract.image_to_string(image, lang="hin")
        return text.strip() if text.strip() else "âŒ No text detected."
    except Exception:
        return "âŒ Error processing image."

if "message_log" not in st.session_state:
    st.session_state.message_log = [{"role": "ai", "content": "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¤¾ AI à¤¡à¥‰à¤•à¥à¤Ÿà¤° à¤¹à¥‚à¤à¥¤ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤? ğŸ¤–ğŸ’‰"}]

chat_container = st.container()

col1, col2 = st.columns([4, 1])
with col1:
    user_query = st.chat_input("à¤…à¤ªà¤¨à¥‡ à¤²à¤•à¥à¤·à¤£ à¤¬à¤¤à¤¾à¤à¤‚... ğŸ¤’ğŸ’Š")
with col2:
    if st.button("ğŸ™ï¸ à¤¬à¥‹à¤²à¤•à¤° à¤¬à¤¤à¤¾à¤à¤‚"):
        user_query = recognize_speech()
        st.text(f"ğŸ—£ï¸ à¤†à¤ªà¤¨à¥‡ à¤•à¤¹à¤¾: {user_query}")

if user_query:
    with st.spinner("ğŸ§  AI à¤¡à¥‰à¤•à¥à¤Ÿà¤° à¤¸à¥‹à¤š à¤°à¤¹à¤¾ à¤¹à¥ˆ..."):
        ai_response = ai_doctor.invoke(user_query)
        if hasattr(ai_response, "content"):
            ai_response = ai_response.content.strip()
        st.session_state.message_log.append({"role": "ai", "content": ai_response})
        st.chat_message("ai").markdown(ai_response)
        speak_text(ai_response, lang="hi")

uploaded_file = st.file_uploader("ğŸ“¤ à¤®à¥‡à¤¡à¤¿à¤•à¤² à¤°à¤¿à¤ªà¥‹à¤°à¥à¤Ÿ à¤…à¤ªà¤²à¥‹à¤¡ à¤•à¤°à¥‡à¤‚ (PDF/à¤›à¤µà¤¿)", type=["pdf", "png", "jpg", "jpeg"])
if uploaded_file:
    report_text = extract_text_from_pdf(uploaded_file) if uploaded_file.type == "application/pdf" else extract_text_from_image(uploaded_file)
    st.write("ğŸ“„ à¤¨à¤¿à¤•à¤¾à¤²à¤¾ à¤—à¤¯à¤¾ à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ:", report_text)
    if report_text:
        with st.spinner("ğŸ”¬ à¤®à¥‡à¤¡à¤¿à¤•à¤² à¤°à¤¿à¤ªà¥‹à¤°à¥à¤Ÿ à¤•à¤¾ à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤¹à¥‹ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."):
            report_analysis = ai_doctor.invoke(f"à¤‡à¤¸ à¤®à¥‡à¤¡à¤¿à¤•à¤² à¤°à¤¿à¤ªà¥‹à¤°à¥à¤Ÿ à¤•à¤¾ à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤•à¤°à¥‡à¤‚: {report_text}")
            if hasattr(report_analysis, "content"):
                report_analysis = report_analysis.content.strip()
            st.write("ğŸ’Š AI à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£:", report_analysis)
            speak_text(report_analysis, lang="hi")
